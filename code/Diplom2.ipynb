{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqentIhz98Hs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import IPython\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Deep learning libraries\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "# Setting seeds for reproducibility\n",
        "seed = 69\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jKos98BChMG"
      },
      "outputs": [],
      "source": [
        "def change_contrast(img):\n",
        "    return tf.image.adjust_contrast(img, 1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RqHzSyuA_zI"
      },
      "outputs": [],
      "source": [
        "input_path = '/content/drive/My Drive/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfPIuPLzBEjR",
        "outputId": "d0b49217-dad6-4c7f-b6ab-673c467c48f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_wk8OqzBGII",
        "outputId": "90318a09-ec98-4c31-a865-0506471fc983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set: train, 03 images: 612, 48 images: 1323, 913 images: 1343, 1418 images: 476\n",
            "Set: val, 03 images: 39, 48 images: 83, 913 images: 85, 1418 images: 31\n",
            "Set: test, 03 images: 115, 48 images: 248, 913 images: 251, 1418 images: 89\n"
          ]
        }
      ],
      "source": [
        "for st in ['train', 'val', 'test']:\n",
        "    n_03 = len(os.listdir(input_path + '/' + st + '/03'))\n",
        "    n_48 = len(os.listdir(input_path + '/' + st + '/48'))\n",
        "    n_913 = len(os.listdir(input_path + '/' + st + '/913'))\n",
        "    n_1418 = len(os.listdir(input_path + '/' + st + '/1418'))\n",
        "    print('Set: {}, 03 images: {}, 48 images: {}, 913 images: {}, 1418 images: {}'.format(st, n_03, n_48, n_913, n_1418))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd057gc1EiPg"
      },
      "outputs": [],
      "source": [
        "def process_data(img_dims, batch_size):\n",
        "    train_datagen = ImageDataGenerator(rotation_range=5, \n",
        "                                       rescale=1./255, \n",
        "                                       zoom_range=0.07, \n",
        "                                       width_shift_range=0.05,\n",
        "                                       height_shift_range=0.05,\n",
        "                                       shear_range=0.07,\n",
        "                                       preprocessing_function=change_contrast)\n",
        "    \n",
        "    test_val_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          preprocessing_function=change_contrast)\n",
        "    \n",
        "    train_gen = train_datagen.flow_from_directory(directory=input_path+ '/' + 'train', \n",
        "                                                  target_size=(img_dims, img_dims), \n",
        "                                                  batch_size=batch_size, \n",
        "                                                  class_mode='categorical', \n",
        "                                                  shuffle=True)\n",
        "\n",
        "    test_gen = test_val_datagen.flow_from_directory(directory=input_path+ '/' + 'test', \n",
        "                                                    target_size=(img_dims, img_dims), \n",
        "                                                    batch_size=batch_size, \n",
        "                                                    class_mode='categorical', \n",
        "                                                    shuffle=False)\n",
        "    \n",
        "    test_data = []\n",
        "    test_labels = []\n",
        "\n",
        "    for cond in ['/03/', '/48/', '/913/', '/1418/']:\n",
        "        for img in (os.listdir(input_path + '/' + 'test' + cond)):\n",
        "            img = cv2.imread(input_path+ '/' + 'test'+cond+img)\n",
        "            img = cv2.resize(img, (img_dims, img_dims))\n",
        "            img = change_contrast(img)\n",
        "            if cond=='/48/':\n",
        "                label = 1\n",
        "            elif cond=='/913/':\n",
        "                label = 2\n",
        "            elif cond=='/03/':\n",
        "                label = 0\n",
        "            elif cond=='/1418/':\n",
        "                label = 3\n",
        "            test_data.append(img)\n",
        "            test_labels.append(label)\n",
        "    test_data = np.array(test_data) / 255.0\n",
        "    test_labels = np.array(test_labels)\n",
        "    \n",
        "    return train_gen, test_gen, test_data, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yri8yVRFgWy",
        "outputId": "802817ac-b36e-4ca4-cf5d-c41af0a7b588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3754 images belonging to 4 classes.\n",
            "Found 703 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "img_dims = 224\n",
        "batch_size = 64\n",
        "\n",
        "# Getting the data\n",
        "train_gen, test_gen, test_data, test_labels = process_data(img_dims, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3WsbOFgyoUD",
        "outputId": "e9cd5249-4b58-4309-a8a0-1995079a2013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'LRFinder'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Total 71 (delta 0), reused 0 (delta 0), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WittmannF/LRFinder.git\n",
        "from LRFinder.keras_callback import LRFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KznKzFE-yrKS"
      },
      "outputs": [],
      "source": [
        "lr_finder = LRFinder(min_lr=1e-4, max_lr=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNoiwR3SXPsP"
      },
      "outputs": [],
      "source": [
        "pip install -U keras-efficientnet-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_TGorZIXXSX"
      },
      "outputs": [],
      "source": [
        "import keras_efficientnet_v2\n",
        "model = keras_efficientnet_v2.EfficientNetV2L(pretrained=\"imagenet\", num_classes=4, include_preprocessing=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbrY3unDCef7"
      },
      "outputs": [],
      "source": [
        " base_model = tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(img_dims, img_dims, 3))\n",
        "#base_model = tf.keras.applications.DenseNet201(include_top=False, weights='imagenet', input_tensor=None, input_shape=(img_dims, img_dims, 3), pooling=None)\n",
        "base_model.trainable = True\n",
        "head_model = base_model.output\n",
        "head_model = Flatten()(head_model)\n",
        "head_model = Dense(512, activation='relu')(head_model)\n",
        "head_model = Dropout(0.3)(head_model)\n",
        "head_model = BatchNormalization()(head_model)\n",
        "head_model = Dense(256, activation='relu')(head_model)\n",
        "head_model = Dropout(0.2)(head_model)\n",
        "head_model = BatchNormalization()(head_model)\n",
        "predictions = Dense(4, activation='softmax')(head_model)\n",
        "model = tf.keras.Model(base_model.input, outputs=predictions)\n",
        "\n",
        "opt = Adam(learning_rate=1e-3)\n",
        "class_weight = {0: 2.194,\n",
        "                1: 1.015,\n",
        "                2: 1,\n",
        "                3: 2.821}\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.05, patience=6)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=3, mode='auto')\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1ecd0LVgKpt",
        "outputId": "c343a7e0-06f6-425d-9cc2-b34b84cdf33a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
            "4334752/4334752 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.applications.MobileNetV3Small(\n",
        "    input_shape=(img_dims, img_dims, 3), alpha=1.0, minimalistic=False, include_top=False,\n",
        "    weights='imagenet', input_tensor=None, classes=4, pooling=None,\n",
        "    dropout_rate=0.2, classifier_activation='softmax',\n",
        "    include_preprocessing=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lxaiyouZF42"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.applications.regnet.RegNetY032(\n",
        "    model_name='regnety320', include_top=True, include_preprocessing=False,\n",
        "    weights=None , input_tensor=None, input_shape=None, pooling=None,\n",
        "    classes=4, classifier_activation='softmax'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjWshJRK6hOJ"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS9pYOUTsZ_v"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for layer in model.layers:\n",
        "  print(i, layer.name, layer.trainable)\n",
        "  i = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilRV484EvgD-"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ydNloVQnowJZ"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model, to_file='model.png', show_shapes=False, show_dtype=False,\n",
        "    show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96,\n",
        "    layer_range=None, show_layer_activations=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVmmjsaYYO0e"
      },
      "outputs": [],
      "source": [
        "model.trainable = True\n",
        "for layer in model.layers:\n",
        "  layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbSPaNsVUjEG"
      },
      "outputs": [],
      "source": [
        "opt = Adam(learning_rate=1e-2)\n",
        "class_weight = {0: 2.194,\n",
        "                1: 1.015,\n",
        "                2: 1.0,\n",
        "                3: 2.821}\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.05, patience=4)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='loss', factor=0.3, patience=3, mode='auto')\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z15l0lbVgzN5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "            train_gen, steps_per_epoch=train_gen.samples // batch_size, \n",
        "            epochs=5, callbacks=[lr_finder],\n",
        "            class_weight=class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wEt7fg4wp-Q",
        "outputId": "e467e9ce-e52a-4e35-efd4-28aa34020fc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "initial_learning_rate = 0.1\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "opt = tf.keras.optimizers.Adam(lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6p5pjkoywsw"
      },
      "outputs": [],
      "source": [
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=4, verbose=2, mode='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CyYp8jYeeak"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "            train_gen, steps_per_epoch=train_gen.samples // batch_size, \n",
        "            epochs=5, validation_data=test_gen, \n",
        "            validation_steps=test_gen.samples // batch_size, callbacks=[lr_reduce])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf-hUXcwB5Yj",
        "outputId": "7c2bab4f-1787-4301-c02f-533f48fd7c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/dpdpdp/assets\n"
          ]
        }
      ],
      "source": [
        "tf.keras.models.save_model(model, filepath = '/content/drive/My Drive/dpdpdp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I8_yF6CGN9r"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/My Drive/dpdpdp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXpw1AcGFOc1"
      },
      "outputs": [],
      "source": [
        "model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKY1tnx9FRio"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0ZBctueG0mK"
      },
      "outputs": [],
      "source": [
        "lr_finder = LRFinder(min_lr=1e-5, max_lr=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK8t9H52HJ0F"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "            train_gen, steps_per_epoch=train_gen.samples // batch_size, \n",
        "            epochs=5, callbacks=[lr_finder],\n",
        "            class_weight=class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FdLfLqjVye0"
      },
      "outputs": [],
      "source": [
        "opt = Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "lr_reduce = ReduceLROnPlateau(monitor='loss', factor=0.4, patience=4, verbose=2, mode='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCWHTpx0RBiH"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for layer in model.layers:\n",
        "  print(i, layer.name, layer.trainable)\n",
        "  i = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgVLW38dkft9"
      },
      "outputs": [],
      "source": [
        "class_weight = {0: 2.194,\n",
        "                1: 1.015,\n",
        "                2: 1,\n",
        "                3: 2.821}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq5mbiALVQic"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "            train_gen, steps_per_epoch=train_gen.samples // batch_size,\n",
        "            epochs=50, validation_data=test_gen,\n",
        "            validation_steps=test_gen.samples // batch_size, callbacks=[lr_reduce],\n",
        "            class_weight=class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCkiM-S-wJ3n",
        "outputId": "8eb3724e-d4a5-4327-fd35-e8979b88ff3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/DiplomPredict/assets\n"
          ]
        }
      ],
      "source": [
        "model.save(\"/content/drive/My Drive/dddd\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJcMa5jmJgkn"
      },
      "outputs": [],
      "source": [
        "lr_finder = LRFinder(min_lr=1e-4, max_lr=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJU_1wPdFj-q"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "            train_gen, steps_per_epoch=train_gen.samples // batch_size, \n",
        "            epochs=5, callbacks=[lr_finder],\n",
        "            class_weight=class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU-MksWQcB42"
      },
      "outputs": [],
      "source": [
        "predIdxs = model.predict(test_data)\n",
        "predIdxs = np.argmax(predIdxs,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI-alHtrcKqW"
      },
      "outputs": [],
      "source": [
        "cm=confusion_matrix(test_labels, predIdxs, labels =[0, 1, 2, 3])\n",
        "print(cm.shape)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqmmA8wNce1F"
      },
      "outputs": [],
      "source": [
        "tp25 = cm[0][0]\n",
        "tp50 = cm[1][1]\n",
        "tp75 = cm[2][2]\n",
        "tp100 = cm[3][3]\n",
        "\n",
        "fn25 = cm[0][1] + cm[0][2] + cm[0][3]\n",
        "fn50 = cm[1][0] + cm[1][2] + cm[1][3]\n",
        "fn75 = cm[2][0] + cm[2][1] + cm[2][3]\n",
        "fn100 = cm[3][0] + cm[3][1] + cm[3][2]\n",
        "\n",
        "fp25 = cm[1][0] + cm[2][0] + cm[3][0]\n",
        "fp50 = cm[0][1] + cm[2][1] + cm[3][1]\n",
        "fp75 = cm[0][2] + cm[1][2] + cm[3][2]\n",
        "fp100 = cm[0][3] + cm[1][3] + cm[2][3]\n",
        "\n",
        "precision_25 = tp25/(tp25+fp25)*100\n",
        "precision_50 = tp50/(tp50+fp50)*100\n",
        "precision_75 = tp75/(tp75+fp75)*100\n",
        "precision_100 = tp100/(tp100+fp100)*100\n",
        "\n",
        "recall_25 = tp25/(tp25+fn25)*100\n",
        "recall_50 = tp50/(tp50+fn50)*100\n",
        "recall_75 = tp75/(tp75+fn75)*100\n",
        "recall_100 = tp100/(tp100+fn100)*100\n",
        "\n",
        "print('Precision 25: {:.2f}%'.format(precision_25))\n",
        "print('Recall 25: {:.2f}%'.format(recall_25))\n",
        "print()\n",
        "\n",
        "print('Precision 50: {:.2f}%'.format(precision_50))\n",
        "print('Recall 50: {:.2f}%'.format(recall_50))\n",
        "print()\n",
        "\n",
        "print('Precision 75: {:.2f}%'.format(precision_75))\n",
        "print('Recall 75: {:.2f}%'.format(recall_75))\n",
        "print()\n",
        "\n",
        "print('Precision 100: {:.2f}%'.format(precision_100))\n",
        "print('Recall 100: {:.2f}%'.format(recall_100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UnQXctGhcivw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NGqpxikoc7ae"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Diplom2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}